{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bcad126",
   "metadata": {},
   "source": [
    "è¿™æ¬¡èƒ½è·‘èµ·æ¥å°±ç®—æˆåŠŸï¼Œä½†æ˜¯æœ€åå¾—åˆ°çš„è¿œè¿œè¶…å‡ºæˆ‘çš„é¢„æœŸï¼Œæ‰€ä»¥åœ¨æ­¤é€æ­¥æ€»ç»“ï¼Œå¥½å½»åº•ç»“å°¾"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66870c87",
   "metadata": {},
   "source": [
    "é¦–å…ˆåœ¨è¿™é‡Œæ„Ÿè°¢gptçˆ¹çš„å…¨åŠ›å¸®åŠ©ï¼Œæ„Ÿè°¢ä½ ä¸åŒå…¶çƒ¦åœ°ç»™æˆ‘è§£ç­”ï¼Œè°¢è°¢ä½ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835bd7b0",
   "metadata": {},
   "source": [
    "## æ•°æ®é›†å‡†å¤‡"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e088f5",
   "metadata": {},
   "source": [
    "æˆ‘æ˜¯åœ¨kaggleä¸Šé¢æœç´¢çš„æ•°æ®é›†ï¼Œæ˜¯tedçš„æ¼”è®²csvï¼Œæœç´¢æ•°æ®é›†åº”è¯¥ä¸ç®—éš¾äº‹ï¼Œæˆ‘ä»…ä»…åœ¨è¿™é‡Œé™„ä¸Šç½‘ç«™\n",
    "https://www.kaggle.com/datasets/rounakbanik/ted-talks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ece873a",
   "metadata": {},
   "source": [
    "### æ•°æ®æ¸…æ´—"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca24eb6",
   "metadata": {},
   "source": [
    "æˆ‘æƒ³ä¸‹é¢ä¸€ä¸ªå‡½æ•°èƒ½è§£é‡Šä¸€åˆ‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87f51f1",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # å»é™¤æ‰€æœ‰ (...) å’Œ [...] ä¸­çš„å†…å®¹ï¼ŒåŒ…æ‹¬æ‹¬å·æœ¬èº«\n",
    "    text = re.sub(r'\\([^)]*\\)', '', text)\n",
    "    text = re.sub(r'\\[[^\\]]*\\]', '', text)\n",
    "    # æ›¿æ¢å¤šä¸ªç©ºæ ¼ä¸ºä¸€ä¸ªç©ºæ ¼\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6402044",
   "metadata": {},
   "source": [
    "æˆ‘æŠŠcsvæ”¾åˆ°ä¸€ä¸ªæ–‡ä»¶å¤¹é‡Œé¢äº†æ–¹ä¾¿é›†ä¸­å¤„ç†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c0788c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# éå†æ–‡ä»¶å¤¹ä¸‹æ‰€æœ‰ CSV æ–‡ä»¶\n",
    "for csv_file in csv_dir.glob(\"*.csv\"):\n",
    "    df = pd.read_csv(csv_file)\n",
    "    # è‡ªåŠ¨é€‰æ‹©åˆé€‚çš„æ–‡æœ¬åˆ—\n",
    "    column = 'transcript' if 'transcript' in df.columns else 'content' if 'content' in df.columns else None\n",
    "    if column is None:\n",
    "        print(f\"âš ï¸ è·³è¿‡æ–‡ä»¶ï¼ˆæ— åˆé€‚æ–‡æœ¬åˆ—ï¼‰: {csv_file.name}\")\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f44bb67",
   "metadata": {},
   "source": [
    "å…·ä½“å®ç°åœ¨ä»£ç é‡Œé¢æœ‰ï¼Œå†æ¬¡æ„Ÿè°¢gptçˆ¹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab57eb3b",
   "metadata": {},
   "source": [
    "### æ•°æ®é¢„å¤„ç†"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6840eb86",
   "metadata": {},
   "source": [
    "è¿™é‡Œå·²ç»å¾—åˆ°äº†åˆæ­¥å¯ç”¨çš„æ•°æ®ï¼Œä½†æ˜¯ä¸ºäº†å¢å¼ºæ•°æ®å¯ç”¨æ€§ï¼Œéœ€è¦è¿›è¡Œé¢„å¤„ç†å¢å¼º"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12401199",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 2. æ·»åŠ ç‰¹æ®Š tokenï¼š<s> å¼€å¤´ï¼Œ<eos> ç»“å°¾\n",
    "# å°†æ¯ä¸€è¡Œå¤„ç†ä¸ºå¥å­ï¼ˆå¯æ ¹æ®éœ€è¦æ›¿æ¢ä¸ºå…¶ä»–åˆ†å‰²æ–¹æ³•ï¼‰\n",
    "lines = raw_text.strip().splitlines()\n",
    "tokenized_lines = [[\"<s>\"] + line.strip().split() + [\"<eos>\"] for line in lines]\n",
    "words = [word for line in tokenized_lines for word in line]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286b9931",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 4. ä¿å­˜è¯è¡¨\n",
    "with open(\"transformer!/gpt/vocab.pkl\", \"wb\") as f:\n",
    "    pickle.dump((stoi, itos), f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7cd9863",
   "metadata": {},
   "source": [
    "ç”¨çš„è¯åµŒå…¥çš„æ–¹æ³•ï¼Œå¾—åˆ°äº†è¯è¡¨vocab.pklï¼Œè¿™ä¸ªæ–‡ä»¶åœ¨transformer/gptæ–‡ä»¶å¤¹ä¸‹,ä½†æ˜¯è¿˜ä¸å¤Ÿï¼Œéœ€è¦å°†å…¶ä½¿å…¶ç¼–ç "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da97d7d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 5. ç¼–ç æ–‡æœ¬ä¸º token ID\n",
    "def encode(word_list):\n",
    "    return [stoi.get(w, stoi[\"<unk>\"]) for w in word_list]\n",
    "\n",
    "data_ids = torch.tensor(encode(words), dtype=torch.long)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6805185",
   "metadata": {},
   "source": [
    "ç„¶åæ‰æ˜¯åˆ’åˆ†è®­ç»ƒé›†å’ŒéªŒè¯é›†å¾—åˆ°trainå’Œval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef703420",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 6. åˆ’åˆ†è®­ç»ƒ/éªŒè¯é›†\n",
    "n = int(0.9 * len(data_ids))\n",
    "train_data = data_ids[:n]\n",
    "val_data = data_ids[n:]\n",
    "\n",
    "# 7. ä¿å­˜ç¼–ç åçš„æ•°æ®\n",
    "Path(\"transformer!/gpt/data\").mkdir(parents=True, exist_ok=True)\n",
    "torch.save(train_data, \"transformer!/gpt/data/train.pt\")\n",
    "torch.save(val_data, \"transformer!/gpt/data/val.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f90335",
   "metadata": {},
   "source": [
    "## æ¨¡å‹çš„æ„å»º"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba94dd5f",
   "metadata": {},
   "source": [
    "å®šä¹‰å¥½å‚æ•°çš„ä¸œè¥¿"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6db6c39",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "class GPTConfig:\n",
    "    # åˆå§‹åŒ–æ–¹æ³•ï¼Œç”¨äºåˆ›å»ºGPTConfigç±»çš„å®ä¾‹\n",
    "    def __init__(self, vocab_size, block_size=128, n_layer=4, n_head=4, n_embd=256, dropout=0.1):\n",
    "        # vocab_size: è¯æ±‡è¡¨å¤§å°ï¼Œè¡¨ç¤ºæ¨¡å‹å¯ä»¥å¤„ç†çš„å”¯ä¸€æ ‡è®°çš„æ•°é‡\n",
    "        self.vocab_size = vocab_size\n",
    "        # block_size: ä¸Šä¸‹æ–‡çª—å£å¤§å°ï¼Œè¡¨ç¤ºæ¨¡å‹åœ¨ä¸€æ¬¡å‰å‘ä¼ æ’­ä¸­å¯ä»¥å¤„ç†çš„åºåˆ—é•¿åº¦\n",
    "        self.block_size = block_size\n",
    "        # n_layer: Transformerå±‚çš„æ•°é‡ï¼Œè¡¨ç¤ºæ¨¡å‹çš„æ·±åº¦\n",
    "        self.n_layer = n_layer\n",
    "        # n_head: å¤šå¤´æ³¨æ„åŠ›æœºåˆ¶ä¸­çš„æ³¨æ„åŠ›å¤´æ•°ï¼Œè¡¨ç¤ºæ¯ä¸ªæ³¨æ„åŠ›å¤´è´Ÿè´£çš„éƒ¨åˆ†æ³¨æ„åŠ›è®¡ç®—\n",
    "        self.n_head = n_head\n",
    "        # n_embd: åµŒå…¥ç»´åº¦ï¼Œè¡¨ç¤ºæ¯ä¸ªæ ‡è®°çš„å‘é‡è¡¨ç¤ºçš„ç»´åº¦\n",
    "        self.n_embd = n_embd\n",
    "        # dropout: Dropoutç‡ï¼Œç”¨äºé˜²æ­¢è¿‡æ‹Ÿåˆï¼Œè¡¨ç¤ºåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­éšæœºä¸¢å¼ƒçš„æ¯”ä¾‹\n",
    "        self.dropout = dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295d526b",
   "metadata": {},
   "source": [
    "å…³é”®çš„è‡ªæ³¨æ„åŠ›æœºåˆ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762ce2b5",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        # åˆå§‹åŒ–çˆ¶ç±»\n",
    "        super().__init__()\n",
    "        # å®šä¹‰çº¿æ€§å˜æ¢å±‚ï¼Œç”¨äºè®¡ç®—key\n",
    "        self.key = nn.Linear(config.n_embd, config.n_embd)\n",
    "        # å®šä¹‰çº¿æ€§å˜æ¢å±‚ï¼Œç”¨äºè®¡ç®—query\n",
    "        self.query = nn.Linear(config.n_embd, config.n_embd)\n",
    "        # å®šä¹‰çº¿æ€§å˜æ¢å±‚ï¼Œç”¨äºè®¡ç®—value\n",
    "        self.value = nn.Linear(config.n_embd, config.n_embd)\n",
    "        # å®šä¹‰çº¿æ€§å˜æ¢å±‚ï¼Œç”¨äºè¾“å‡ºæŠ•å½±\n",
    "        self.proj = nn.Linear(config.n_embd, config.n_embd)\n",
    "        # å®šä¹‰dropoutå±‚ï¼Œç”¨äºé˜²æ­¢è¿‡æ‹Ÿåˆ\n",
    "        self.dropout = nn.Dropout(config.dropout)\n",
    "        # å®šä¹‰æ³¨æ„åŠ›å¤´çš„æ•°é‡\n",
    "        self.n_head = config.n_head\n",
    "\n",
    "    def forward(self, x):\n",
    "        # è·å–è¾“å…¥çš„æ‰¹æ¬¡å¤§å°ã€åºåˆ—é•¿åº¦å’ŒåµŒå…¥ç»´åº¦\n",
    "        B, T, C = x.size()\n",
    "        # è®¡ç®—æ¯ä¸ªæ³¨æ„åŠ›å¤´çš„ç»´åº¦\n",
    "        head_dim = C // self.n_head\n",
    "        # è®¡ç®—keyï¼Œå¹¶è°ƒæ•´å½¢çŠ¶ä»¥é€‚åº”å¤šå¤´æ³¨æ„åŠ›\n",
    "        k = self.key(x).view(B, T, self.n_head, head_dim).transpose(1, 2)\n",
    "        # è®¡ç®—queryï¼Œå¹¶è°ƒæ•´å½¢çŠ¶ä»¥é€‚åº”å¤šå¤´æ³¨æ„åŠ›\n",
    "        q = self.query(x).view(B, T, self.n_head, head_dim).transpose(1, 2)\n",
    "        # è®¡ç®—valueï¼Œå¹¶è°ƒæ•´å½¢çŠ¶ä»¥é€‚åº”å¤šå¤´æ³¨æ„åŠ›\n",
    "        v = self.value(x).view(B, T, self.n_head, head_dim).transpose(1, 2)\n",
    "\n",
    "        # è®¡ç®—æ³¨æ„åŠ›åˆ†æ•°\n",
    "        att = (q @ k.transpose(-2, -1)) / (head_dim ** 0.5)\n",
    "        # åˆ›å»ºæ©ç çŸ©é˜µï¼Œç”¨äºé˜²æ­¢æœªæ¥ä¿¡æ¯çš„æ³„éœ²\n",
    "        mask = torch.tril(torch.ones(T, T, device=x.device)).unsqueeze(0).unsqueeze(0)\n",
    "        # å°†æ³¨æ„åŠ›åˆ†æ•°ä¸­ä¸éœ€è¦çš„éƒ¨åˆ†è®¾ä¸ºè´Ÿæ— ç©·\n",
    "        att = att.masked_fill(mask == 0, float('-inf'))\n",
    "        # åº”ç”¨softmaxå‡½æ•°ï¼Œå¾—åˆ°æ³¨æ„åŠ›æƒé‡\n",
    "        att = F.softmax(att, dim=-1)\n",
    "        # åº”ç”¨dropout\n",
    "        att = self.dropout(att)\n",
    "        # è®¡ç®—è¾“å‡º\n",
    "        out = att @ v\n",
    "        # è°ƒæ•´è¾“å‡ºå½¢çŠ¶\n",
    "        out = out.transpose(1, 2).contiguous().view(B, T, C)\n",
    "        # åº”ç”¨è¾“å‡ºæŠ•å½±\n",
    "        return self.proj(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1a5d05",
   "metadata": {},
   "source": [
    "ç„¶åä¸€ä¸ªå®Œæ•´çš„transformerå—"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f83bfe7",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    # å®šä¹‰TransformerBlockç±»ï¼Œç»§æ‰¿è‡ªnn.Module\n",
    "    def __init__(self, config):\n",
    "        # åˆå§‹åŒ–å‡½æ•°ï¼Œæ¥æ”¶é…ç½®å‚æ•°config\n",
    "        super().__init__()\n",
    "        # è°ƒç”¨çˆ¶ç±»nn.Moduleçš„åˆå§‹åŒ–å‡½æ•°\n",
    "        self.sa = SelfAttention(config)\n",
    "        # åˆå§‹åŒ–è‡ªæ³¨æ„åŠ›æœºåˆ¶æ¨¡å—SelfAttentionï¼Œä¼ å…¥é…ç½®å‚æ•°config\n",
    "        self.ln1 = nn.LayerNorm(config.n_embd)\n",
    "        # åˆå§‹åŒ–ç¬¬ä¸€ä¸ªå±‚å½’ä¸€åŒ–æ¨¡å—LayerNormï¼Œè¾“å…¥ç»´åº¦ä¸ºconfig.n_embd\n",
    "        self.ff = nn.Sequential(\n",
    "            # åˆå§‹åŒ–å‰é¦ˆç¥ç»ç½‘ç»œæ¨¡å—ï¼ŒåŒ…å«ä»¥ä¸‹å±‚ï¼š\n",
    "            nn.Linear(config.n_embd, 4 * config.n_embd),\n",
    "            # çº¿æ€§å±‚ï¼Œå°†è¾“å…¥ç»´åº¦ä»config.n_embdå˜æ¢åˆ°4å€çš„config.n_embd\n",
    "            nn.ReLU(),\n",
    "            # ReLUæ¿€æ´»å‡½æ•°\n",
    "            nn.Linear(4 * config.n_embd, config.n_embd),\n",
    "            # çº¿æ€§å±‚ï¼Œå°†è¾“å…¥ç»´åº¦ä»4å€çš„config.n_embdå˜æ¢å›config.n_embd\n",
    "            nn.Dropout(config.dropout),\n",
    "            # Dropoutå±‚ï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆï¼Œä¸¢å¼ƒç‡ä¸ºconfig.dropout\n",
    "        )\n",
    "        self.ln2 = nn.LayerNorm(config.n_embd)\n",
    "\n",
    "        # åˆå§‹åŒ–ç¬¬äºŒä¸ªå±‚å½’ä¸€åŒ–æ¨¡å—LayerNormï¼Œè¾“å…¥ç»´åº¦ä¸ºconfig.n_embd\n",
    "    def forward(self, x):\n",
    "        # å®šä¹‰å‰å‘ä¼ æ’­å‡½æ•°ï¼Œæ¥æ”¶è¾“å…¥x\n",
    "        x = x + self.sa(self.ln1(x))\n",
    "        # è®¡ç®—è‡ªæ³¨æ„åŠ›æœºåˆ¶è¾“å‡ºï¼Œå¹¶è¿›è¡Œæ®‹å·®è¿æ¥ï¼Œè¾“å…¥xç»è¿‡ç¬¬ä¸€ä¸ªå±‚å½’ä¸€åŒ–åä¼ å…¥è‡ªæ³¨æ„åŠ›æ¨¡å—\n",
    "        x = x + self.ff(self.ln2(x))\n",
    "        # è®¡ç®—å‰é¦ˆç¥ç»ç½‘ç»œè¾“å‡ºï¼Œå¹¶è¿›è¡Œæ®‹å·®è¿æ¥ï¼Œè¾“å…¥xç»è¿‡ç¬¬äºŒä¸ªå±‚å½’ä¸€åŒ–åä¼ å…¥å‰é¦ˆç¥ç»ç½‘ç»œæ¨¡å—\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4d845e",
   "metadata": {},
   "source": [
    "å®Œæ•´çš„ç±»"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebde051",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "class GPT(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        # åˆå§‹åŒ–çˆ¶ç±»nn.Module\n",
    "        super().__init__()\n",
    "        # åˆ›å»ºè¯åµŒå…¥å±‚ï¼Œå°†è¯æ±‡è¡¨ä¸­çš„æ¯ä¸ªè¯æ˜ å°„åˆ°n_embdç»´çš„å‘é‡\n",
    "        self.token_embed = nn.Embedding(config.vocab_size, config.n_embd)\n",
    "        # åˆ›å»ºä½ç½®åµŒå…¥å±‚ï¼Œå°†åºåˆ—ä¸­çš„æ¯ä¸ªä½ç½®æ˜ å°„åˆ°n_embdç»´çš„å‘é‡\n",
    "        self.pos_embed = nn.Embedding(config.block_size, config.n_embd)\n",
    "        # åˆ›å»ºå¤šä¸ªTransformerBlockï¼Œå¹¶ä½¿ç”¨nn.Sequentialå°†å®ƒä»¬ä¸²è”èµ·æ¥\n",
    "        self.blocks = nn.Sequential(*[TransformerBlock(config) for _ in range(config.n_layer)])\n",
    "        # åˆ›å»ºå±‚å½’ä¸€åŒ–å±‚ï¼Œç”¨äºå¯¹æœ€åçš„è¾“å‡ºè¿›è¡Œå½’ä¸€åŒ–å¤„ç†\n",
    "        self.ln_f = nn.LayerNorm(config.n_embd)\n",
    "        # åˆ›å»ºçº¿æ€§å±‚ï¼Œå°†n_embdç»´çš„å‘é‡æ˜ å°„åˆ°è¯æ±‡è¡¨å¤§å°çš„å‘é‡ï¼Œç”¨äºç”Ÿæˆé¢„æµ‹\n",
    "        self.head = nn.Linear(config.n_embd, config.vocab_size)\n",
    "\n",
    "    def forward(self, idx):\n",
    "        # è·å–è¾“å…¥çš„æ‰¹æ¬¡å¤§å°Bå’Œåºåˆ—é•¿åº¦T\n",
    "        B, T = idx.size()\n",
    "        # åˆ›å»ºä¸€ä¸ªä»0åˆ°T-1çš„åºåˆ—ï¼Œè¡¨ç¤ºä½ç½®ä¿¡æ¯ï¼Œå¹¶å°†å…¶ç§»åŠ¨åˆ°ä¸è¾“å…¥ç›¸åŒçš„è®¾å¤‡ä¸Š\n",
    "        pos = torch.arange(T, device=idx.device)\n",
    "        # å°†è¾“å…¥çš„ç´¢å¼•é€šè¿‡è¯åµŒå…¥å±‚å’Œä½ç½®åµŒå…¥å±‚ï¼Œå¾—åˆ°åµŒå…¥å‘é‡ï¼Œå¹¶è¿›è¡Œç›¸åŠ \n",
    "        x = self.token_embed(idx) + self.pos_embed(pos)\n",
    "        # å°†åµŒå…¥å‘é‡é€šè¿‡å¤šä¸ªTransformerBlockè¿›è¡Œå‰å‘ä¼ æ’­\n",
    "        x = self.blocks(x)\n",
    "        # å¯¹æœ€åçš„è¾“å‡ºè¿›è¡Œå±‚å½’ä¸€åŒ–å¤„ç†\n",
    "        x = self.ln_f(x)\n",
    "        # å°†å½’ä¸€åŒ–åçš„è¾“å‡ºé€šè¿‡çº¿æ€§å±‚ï¼Œå¾—åˆ°æœ€ç»ˆçš„é¢„æµ‹ç»“æœ\n",
    "        return self.head(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614c4533",
   "metadata": {},
   "source": [
    "æ„å»ºæ¨¡å‹å¾ˆç®€å•å•Šæ˜¯ä¸æ˜¯ï¼Œå…¶å®éƒ½æ˜¯gptçˆ¹åšçš„"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fce5b1f",
   "metadata": {},
   "source": [
    "## å‡†å¤‡è®­ç»ƒ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05895aea",
   "metadata": {},
   "source": [
    "ä¸€äº›ç®€å•çš„é…ç½®ï¼Œè¿™é‡Œæˆ‘ç”¨äº†cudaï¼Œæ²¡è¿™ä¸ªçœŸçš„ä¸è¡Œï¼Œè¿˜ç”¨äº†è®­ç»ƒå¯è§†åŒ–tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14d5b01",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 1. ç¯å¢ƒé…ç½®\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "writer = SummaryWriter(log_dir=\"transformer!/gpt/runs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3537e5c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 2. åŠ è½½è¯è¡¨\n",
    "with open(\"transformer!/gpt/vocab.pkl\", \"rb\") as f:\n",
    "    stoi, itos = pickle.load(f)\n",
    "vocab_size = len(stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea7ac42",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 3. è¶…å‚æ•°é…ç½®\n",
    "block_size = 64  # å¥å­é•¿åº¦ï¼ˆå•è¯æ•°ï¼‰\n",
    "n_layer = 8\n",
    "n_head = 8\n",
    "n_embd = 256\n",
    "dropout = 0.1\n",
    "lr = 3e-4\n",
    "batch_size = 32\n",
    "max_steps = 50000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c202d184",
   "metadata": {},
   "source": [
    "è¶…å‚æ•°æ˜¯æœ€å…³é”®çš„éƒ¨åˆ†ï¼Œè¦æ ¹æ®è¦æ±‚é…Œæƒ…è°ƒæ•´ï¼Œæˆ‘æœ€åå› ä¸ºæ–­ç”µå½±å“ï¼Œåªèƒ½è®­ç»ƒäº”ä¸‡ä¸ªå‘¨æœŸï¼Œgpuä¹Ÿæ”¯æ’‘ä¸äº†æ›´é«˜çš„å‚æ•°ï¼Œä½†æ˜¯å·²ç»è¶³å¤Ÿäº†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2b3fda",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 4. åŠ è½½é¢„å¤„ç†æ•°æ®\n",
    "train_data = torch.load(\"transformer!/gpt/data/train.pt\")\n",
    "val_data = torch.load(\"transformer!/gpt/data/val.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143346be",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 5. æ„å»ºæ¨¡å‹\n",
    "config = GPTConfig(vocab_size, block_size, n_layer, n_head, n_embd, dropout)\n",
    "model = GPT(config).to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "scaler = GradScaler()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d01d06",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 6. ç”Ÿæˆè®­ç»ƒæ‰¹æ¬¡\n",
    "def get_batch(data):\n",
    "    ix = torch.randint(0, len(data) - block_size - 1, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    return x.to(device), y.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e989c16",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 7. è®­ç»ƒå¾ªç¯\n",
    "for step in range(max_steps):\n",
    "    x, y = get_batch(train_data)\n",
    "\n",
    "    # AMP æ··åˆç²¾åº¦è®­ç»ƒ\n",
    "    with autocast(device_type='cuda' if torch.cuda.is_available() else 'cpu'):\n",
    "        logits = model(x)\n",
    "        loss = F.cross_entropy(logits.view(-1, vocab_size), y.view(-1))\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    scaler.scale(loss).backward()\n",
    "    scaler.step(optimizer)\n",
    "    scaler.update()\n",
    "\n",
    "    writer.add_scalar(\"Loss/Train\", loss.item(), step)\n",
    "\n",
    "    # éªŒè¯ä¸æ‰“å°\n",
    "    if step % 100 == 0:\n",
    "        model.eval()\n",
    "        with torch.no_grad(), autocast(device_type='cuda' if torch.cuda.is_available() else 'cpu'):\n",
    "            x_val, y_val = get_batch(val_data)\n",
    "            val_logits = model(x_val)\n",
    "            val_loss = F.cross_entropy(val_logits.view(-1, vocab_size), y_val.view(-1))\n",
    "        writer.add_scalar(\"Loss/Val\", val_loss.item(), step)\n",
    "        print(f\"Step {step}, Train Loss: {loss.item():.4f}, Val Loss: {val_loss.item():.4f}\")\n",
    "        torch.cuda.empty_cache()\n",
    "        model.train()\n",
    "\n",
    "# 8. ä¿å­˜æ¨¡å‹\n",
    "torch.save(model.state_dict(), \"transformer!/gpt/gpt_model.pt\")\n",
    "print(\"âœ… è®­ç»ƒå®Œæˆï¼Œæ¨¡å‹å·²ä¿å­˜\")\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa958e3",
   "metadata": {},
   "source": [
    "## ç„¶åæ˜¯è§£è¯»"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb996cdf",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# åŠ è½½è¯è¡¨\n",
    "with open(\"transformer!/gpt/vocab.pkl\", \"rb\") as f:\n",
    "    stoi, itos = pickle.load(f)\n",
    "\n",
    "def encode(s):\n",
    "    return [stoi.get(w, stoi.get('<unk>', 0)) for w in s.split()]\n",
    "\n",
    "def decode(l):\n",
    "    words = [itos[i] for i in l]\n",
    "    return ' '.join(w for w in words if w not in {'<unk>', '<eos>', '<s>'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f920a0f2",
   "metadata": {},
   "source": [
    "è¿™é‡Œæœ‰ä¸ªåˆšæ‰æ²¡è®²åˆ°çš„å…³é”®ä¸œè¥¿unk, eos, sï¼Œæœ‰ä¸¤ä¸ªæ˜¯ç”¨æ¥æ–­å¥çš„ï¼Œè¿˜æœ‰ä¸€ä¸ªç”¨æ¥å¤„ç†é™Œç”Ÿè¯æ±‡ï¼Œå¢å¼ºäº†é²æ£’æ€§"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e61582c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def load_model(model_path, device, block_size=64):\n",
    "    vocab_size = len(stoi)\n",
    "    config = GPTConfig(\n",
    "        vocab_size=vocab_size,\n",
    "        block_size=block_size,\n",
    "        n_layer=8,\n",
    "        n_head=8,\n",
    "        n_embd=256,\n",
    "        dropout=0.1\n",
    "    )\n",
    "    model = GPT(config).to(device)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model.eval()\n",
    "    return model, config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287907ba",
   "metadata": {},
   "source": [
    "ä»¥åŠæœ€æœ€å…³é”®çš„ä¸€ä¸ªå‡½æ•°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d11edf",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def generate(model, config, prompt, device, max_new_tokens=80, temperature=0.7, top_p=0.85, do_sample=True):\n",
    "    # å°†è¾“å…¥çš„promptç¼–ç ä¸ºtensorï¼Œå¹¶ç§»åŠ¨åˆ°æŒ‡å®šè®¾å¤‡ä¸Š\n",
    "    input_ids = torch.tensor(encode(prompt), dtype=torch.long)[None, :].to(device)\n",
    "    # å…‹éš†input_idsä»¥é¿å…ä¿®æ”¹åŸå§‹è¾“å…¥\n",
    "    idx = input_ids.clone()\n",
    "    # è·å–è¾“å…¥çš„é•¿åº¦\n",
    "    input_len = input_ids.shape[1]\n",
    "\n",
    "    # å¾ªç¯ç”Ÿæˆæ–°çš„tokenï¼Œç›´åˆ°è¾¾åˆ°æœ€å¤§é•¿åº¦æˆ–é‡åˆ°ç»“æŸç¬¦\n",
    "    for _ in range(max_new_tokens):\n",
    "        # è·å–å½“å‰è¾“å…¥çš„æœ€åblock_sizeä¸ªtoken\n",
    "        idx_cond = idx[:, -config.block_size:]\n",
    "        # ä½¿ç”¨æ¨¡å‹ç”Ÿæˆlogits\n",
    "        logits = model(idx_cond)\n",
    "        # å¯¹logitsè¿›è¡Œç¼©æ”¾\n",
    "        logits = logits[:, -1, :] / temperature\n",
    "        # è®¡ç®—softmaxæ¦‚ç‡\n",
    "        probs = F.softmax(logits, dim=-1)\n",
    "\n",
    "        # å¦‚æœé€‰æ‹©é‡‡æ ·ç”Ÿæˆ\n",
    "        if do_sample:\n",
    "            # å¯¹æ¦‚ç‡è¿›è¡Œé™åºæ’åº\n",
    "            sorted_probs, sorted_indices = torch.sort(probs, descending=True)\n",
    "            # è®¡ç®—ç´¯ç§¯æ¦‚ç‡\n",
    "            cumulative_probs = torch.cumsum(sorted_probs, dim=-1)\n",
    "            # è·å–ç´¯ç§¯æ¦‚ç‡è¶…è¿‡top_pçš„ä½ç½®\n",
    "            cutoff = cumulative_probs > top_p\n",
    "            # ç¡®ä¿è‡³å°‘æœ‰ä¸€ä¸ªtokençš„æ¦‚ç‡ä¸ä¸º0\n",
    "            cutoff[..., 1:] = cutoff[..., :-1].clone()\n",
    "            cutoff[..., 0] = False\n",
    "            # å°†è¶…è¿‡top_pçš„tokenæ¦‚ç‡è®¾ä¸º0\n",
    "            sorted_probs[cutoff] = 0\n",
    "            # å½’ä¸€åŒ–æ¦‚ç‡\n",
    "            sorted_probs = sorted_probs / sorted_probs.sum(dim=-1, keepdim=True)\n",
    "            # ä½¿ç”¨å¤šé¡¹å¼åˆ†å¸ƒé‡‡æ ·ä¸‹ä¸€ä¸ªtoken\n",
    "            next_token = torch.multinomial(sorted_probs, num_samples=1)\n",
    "            # è·å–å¯¹åº”çš„tokenç´¢å¼•\n",
    "            next_token = sorted_indices.gather(-1, next_token)\n",
    "        else:\n",
    "            # å¦‚æœä¸é‡‡æ ·ï¼Œé€‰æ‹©æ¦‚ç‡æœ€å¤§çš„token\n",
    "            next_token = torch.argmax(probs, dim=-1, keepdim=True)\n",
    "\n",
    "        # å°†ç”Ÿæˆçš„tokenæ·»åŠ åˆ°å½“å‰åºåˆ—ä¸­\n",
    "        idx = torch.cat((idx, next_token), dim=1)\n",
    "\n",
    "        # å¦‚æœç”Ÿæˆ <eos>ï¼Œæå‰ç»“æŸ\n",
    "        if next_token.item() == stoi.get(\"<eos>\", -1):\n",
    "            break\n",
    "\n",
    "    # åªè¿”å›ç”Ÿæˆçš„éƒ¨åˆ†ï¼ˆä¸åŒ…æ‹¬ promptï¼‰\n",
    "    generated = idx[0, input_len:]\n",
    "    return decode(generated.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73e7f9f",
   "metadata": {},
   "source": [
    "æ³¨æ„é‡Œé¢çš„å‚æ•°ï¼Œæˆ‘æ²¡æœ‰ç‰¹åœ°æ‹¿å‡ºæ¥ï¼Œä½†å®é™…ä¸Šä¹Ÿæ˜¯å¾ˆé‡è¦çš„\n",
    "max_new_tokens=80, temperature=0.7, top_p=0.85, do_sample=True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a066bac",
   "metadata": {},
   "source": [
    "ä»€ä¹ˆé™æ¸©å‡æ¸©çš„ï¼Œå‚æ•°ä¸æ‡‚å¯ä»¥é—®gptï¼Œå¯ä»¥æå¤§åœ°å½±å“ç”Ÿæˆçš„ä¸œè¥¿"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460b90bf",
   "metadata": {},
   "source": [
    "æœ€åçš„ä¸»å‡½æ•°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c4e074",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    model, config = load_model(\"transformer!/gpt/gpt_model.pt\", device)\n",
    "\n",
    "    while True:\n",
    "        user_input = input(\"ä½ ï¼š\").strip()\n",
    "        if user_input.lower() == \"exit\":\n",
    "            break\n",
    "\n",
    "        prompt = f\"User: {user_input} Bot:\"\n",
    "        response = generate(model, config, prompt, device)\n",
    "        print(\"ğŸ¤–ï¼š\" + response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3728b7d5",
   "metadata": {},
   "source": [
    "æœ€åæˆ‘é™¤äº†gptçˆ¹æˆ‘è¿˜è¦æ„Ÿè°¢æˆ‘è‡ªå·±ï¼Œæ„Ÿè°¢ç‰¢å¢ï¼Œæˆ‘ä»ä¸¤å¹´å‰ä¸€æ— æ‰€çŸ¥ï¼Œåˆ°ä¸€å¹´å‰åˆšæ¥è§¦aiï¼Œå†åˆ°ç°åœ¨ç»ˆäºèƒ½è·‘ä¸€ä¸ªæ™ºéšœï¼ŒçœŸæ˜¯å¤ªè‰°éš¾äº†ï¼Œæ‰€ä»¥æˆ‘è¦æ„Ÿè°¢ã€‚\n",
    "è¿˜æœ‰æˆ‘çš„å®¶äººä»¬ï¼Œå› ä¸ºæˆ‘çš„ä»»æ€§ï¼Œä¹°äº†å¾ˆè´µçš„ç”µè„‘ï¼Œè¿™ç¡®å®æ˜¯ä¸€ç¬”å·¨æ¬¾ï¼Œå¯¹æˆ‘ä»¬å®¶ï¼Œä½†æ˜¯ä»–ä»¬è¿˜æ˜¯ä¹°äº†ï¼Œç°åœ¨æˆ‘ç»ˆäºç”¨å®ƒåšå‡ºäº†ç‚¹æˆå°±ï¼Œå°†æ¥ä¸€å®šä¹Ÿèƒ½åšæ›´å¤šï¼Œæ¥å›æŠ¥ä¸€ç›´ä»¥æ¥çš„æ”¯æŒï¼Œæ„Ÿè°¢ï¼Œçˆ±ä½ ä»¬"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
