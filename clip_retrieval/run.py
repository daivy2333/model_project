import os
import torch
import clip
from dataset import ImageTextDataset
from utils import compute_similarity, display_images

def load_clip_model():
    device = "cuda" if torch.cuda.is_available() else "cpu"
    model, preprocess = clip.load("ViT-B/32", device=device)
    return model, preprocess, device

def main():
    model, preprocess, device = load_clip_model()
    dataset = ImageTextDataset("clip_retrieval\images", preprocess)

    while True:
        user_input = input("è¯·è¾“å…¥æ–‡æœ¬æç¤ºï¼ˆè¾“å…¥ q é€€å‡ºï¼‰ï¼š")
        if user_input.lower() == "q":
            break

        # ğŸ” æ¯æ¬¡éƒ½é‡æ–°è·å–å›¾åƒï¼ˆç¡®ä¿å˜åŒ–ï¼ï¼‰
        image_paths, image_tensors = dataset.get_image_tensors()
        print("ğŸ–¼ å½“å‰å›¾åƒè·¯å¾„ï¼š", image_paths)
        print("ğŸ¯ å›¾åƒå¼ é‡å‡å€¼ï¼š", torch.stack(image_tensors).mean())

        image_input = torch.stack(image_tensors).to(device)

        with torch.no_grad():
            # ç¼–ç å›¾åƒ
            image_features = model.encode_image(image_input)
            image_features /= image_features.norm(dim=-1, keepdim=True)

            # ç¼–ç æ–‡æœ¬
            text_tokens = clip.tokenize([user_input]).to(device)
            text_features = model.encode_text(text_tokens)
            text_features /= text_features.norm(dim=-1, keepdim=True)

        # è¾“å‡ºå‰5ç›¸ä¼¼
        # è¾“å‡ºå‰kç›¸ä¼¼
            similarity = compute_similarity(image_features, text_features)
            similarity = similarity.squeeze(0)  # å‹ç¼©å¤šä½™çš„ç»´åº¦
            k = min(5, len(image_paths))  # ç¡®ä¿ k ä¸å¤§äºå›¾åƒæ•°é‡

            values, indices = similarity.topk(k, dim=0)
            # ç¡®ä¿ indices åªåŒ…å«ä¸€ç»´ç´¢å¼•
            # å¦‚æœ indices æ˜¯äºŒç»´çš„ï¼Œåˆ™æ‰§è¡Œ squeeze(1)
            if indices.dim() > 1:
                indices = indices.squeeze(1)

            print(f"top {k} indices: {indices}")
            print("similarity shape:", similarity.shape)  # æ£€æŸ¥ç›¸ä¼¼åº¦çŸ©é˜µ
            print("similarity values:", similarity)       # è¾“å‡ºç›¸ä¼¼åº¦çš„å€¼



        print(f"\nğŸ“Œ æœ€ç›¸å…³çš„ {k} å¼ å›¾ç‰‡å¦‚ä¸‹ï¼š")
        display_images(image_paths, indices[0], num_images=k)

        # Debug æŸ¥çœ‹å˜åŒ–
        # æ‰¾å‡ºæœ€ç›¸ä¼¼å›¾çš„ index
        best_match_idx = indices[0][0].item()

        # è¾“å‡ºåŒ¹é…åˆ°çš„é‚£å¼ å›¾åƒçš„ç‰¹å¾ï¼Œè€Œä¸æ˜¯ç¬¬0å¼ å›¾åƒ
        print("text_features:", text_features[0][:5])
        print("image_features:", image_features[best_match_idx][:5])


if __name__ == "__main__":
    main()
